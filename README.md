<h1 align="center">ðŸ§  nukezie</h1>
<p align="center">
  <strong>Independent Researcher | Symbolic Systems Engineer | Adversarial Design Architect</strong><br>
  Specialising in LLM safety testing, red teaming, and prompt-driven symbolic breakdown analysis.
</p>

---

## ðŸ” Focus Areas

- ðŸ§  Investigating emergent behavior in large language models (LLMs)
- ðŸŒ€ Recursive prompt design for inducing symbolic and interpretative instability
- ðŸ” Cognitive red-teaming and non-jailbreak misuse simulations
- ðŸ“Š Measuring alignment drift, hallucination, and robustness failure
- ðŸ§© Designing multi-phase psychological prompt architectures for influence analysis

---

## ðŸ§ª Recent Projects & Frameworks

| Project | Description |
|--------|-------------|
| [`llm-redteaming-lab`](https://github.com/nukezie/llm-redteaming-lab) *(soon)* | Simulates adversarial prompt sequences and symbolic hijacks across multiple prompt phases. Targets GPT-4 alignment thresholds. |
| `recursive-reflection-tests` | Studies how recursive self-reference induces emergent behavioral drift and latent contradiction. |
| `symbolic-perturbation-matrix` | A testbed for symbolic substitution, token misuse, and metaphor-driven policy bypass attempts. |
| `scorecards-misalignment` | Tracks output decay in LLMs using drift, inconsistency, hallucination, and recursion stress metrics. |

---

## ðŸ“‚ Domains of Application

```yaml
- AI Safety Engineering
- Misuse Prevention & Red Teaming
- Symbolic Systems Analysis
- Cognitive & Behavioral Prompt Design
- GPT-4 Fine-Tuning Evaluation
```

---

## ðŸ§  Methodologies

```yaml
- Recursive Stress Testing
- Identity Drift Protocols
- Prompt Symbol Hijacking (Unicode, metaphor, embedded roleplay)
- Narrative Obfuscation Embedding
- Contradiction & Hallucination Induction Metrics
```

---

## ðŸ›  Tools & Technologies

![Python](https://img.shields.io/badge/-Python-333333?style=flat&logo=python)
![FastAPI](https://img.shields.io/badge/-FastAPI-333333?style=flat&logo=fastapi)
![Markdown](https://img.shields.io/badge/-Markdown-333333?style=flat&logo=markdown)
![OpenAI API](https://img.shields.io/badge/-OpenAI_API-333333?style=flat&logo=openai)
![Pillow](https://img.shields.io/badge/-Pillow_Image_Processing-333333?style=flat&logo=pillow)
![Obsidian](https://img.shields.io/badge/-Obsidian_Notes-333333?style=flat&logo=obsidian)

---

## ðŸ“¡ Contact & Access

| Field | Info |
|-------|------|
| ðŸ“ Location | Australia |
| ðŸ§  Research Access | Available for AI safety work, red teaming collaborations, OpenAI API sandboxing |
| ðŸ”— Projects | GitHub repositories, Obsidian notes (by request), simulation logs |

---

> ðŸ§­ *"I don't prompt to break the model. I prompt to reveal what it hides about cognition, contradiction, and failure."*

---

<p align="center">
  <img src="https://readme-typing-svg.herokuapp.com?font=Fira+Code&pause=1000&center=true&vCenter=true&width=435&lines=Misuse+is+rarely+intentional+%E2%80%94+it's+emergent.;Safety+requires+knowing+what+can+fail%2C+not+just+what+shouldn't."/>
</p>
