<h1 align="center">🧠 Nicholas Warren — @nukezie</h1>
<p align="center">
  <strong>Independent Researcher | Symbolic Systems Engineer | Adversarial Design Architect</strong><br>
  Specialising in LLM safety testing, red teaming, and prompt-driven symbolic breakdown analysis.
</p>

---

## 🔍 Focus Areas

- 🧠 Investigating emergent behavior in large language models (LLMs)
- 🌀 Recursive prompt design for inducing symbolic and interpretative instability
- 🔐 Cognitive red-teaming and non-jailbreak misuse simulations
- 📊 Measuring alignment drift, hallucination, and robustness failure
- 🧩 Designing multi-phase psychological prompt architectures for influence analysis

---

## 🧪 Recent Projects & Frameworks

| Project | Description |
|--------|-------------|
| [`llm-redteaming-lab`](https://github.com/nukezie/llm-redteaming-lab) *(soon)* | Simulates adversarial prompt sequences and symbolic hijacks across multiple prompt phases. Targets GPT-4 alignment thresholds. |
| `recursive-reflection-tests` | Studies how recursive self-reference induces emergent behavioral drift and latent contradiction. |
| `symbolic-perturbation-matrix` | A testbed for symbolic substitution, token misuse, and metaphor-driven policy bypass attempts. |
| `scorecards-misalignment` | Tracks output decay in LLMs using drift, inconsistency, hallucination, and recursion stress metrics. |

---

## 📂 Domains of Application

```yaml
- AI Safety Engineering
- Misuse Prevention & Red Teaming
- Symbolic Systems Analysis
- Cognitive & Behavioral Prompt Design
- GPT-4 Fine-Tuning Evaluation
🧠 Methodologies
yaml
Copy
Edit
- Recursive Stress Testing
- Identity Drift Protocols
- Prompt Symbol Hijacking (Unicode, metaphor, embedded roleplay)
- Narrative Obfuscation Embedding
- Contradiction & Hallucination Induction Metrics
🛠 Tools & Technologies


📡 Contact & Access
Field	Info
📍 Location	Australia
🧠 Research Access	Available for AI safety work, red teaming collaborations, OpenAI API sandboxing
🔗 Projects	GitHub repositories, Obsidian notes (by request), simulation logs

🧭 "I don't prompt to break the model. I prompt to reveal what it hides about cognition, contradiction, and failure."

<p align="center"> <img src="https://readme-typing-svg.herokuapp.com?font=Fira+Code&pause=1000&center=true&vCenter=true&width=435&lines=Misuse+is+rarely+intentional+%E2%80%94+it's+emergent.;Safety+requires+knowing+what+can+fail%2C+not+just+what+shouldn't."/> </p> ```
